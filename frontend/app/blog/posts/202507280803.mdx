---
title: '[7/28 - 8/3] GitHub Weekly Digest'
publishedAt: '2025-08-03'
---
## 📌 [Shubhamsaboo/awesome-llm-apps](https://github.com/Shubhamsaboo/awesome-llm-apps)
<Callout>
    Description: Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.\
    🌐 Python｜⭐️ 54,880 | 3584 stars this week
</Callout>
    #### 簡介

* 這是一個精心策劃的出色大型語言模型 (LLM) 應用集合，涵蓋了基於檢索增強生成 (RAG)、AI 代理、多代理團隊、記憶能力控制器 (MCP)、語音代理等技術的應用。
* 收錄的應用使用了來自 OpenAI、Anthropic、Google 以及開源模型（如 DeepSeek、Qwen 或 Llama）的模型，部分可在本地電腦上執行。
* 提供了各種 LLM 應用的實踐案例，展示了 LLM 在不同領域的應用，例如程式碼庫、電子郵件收件箱等等。
* 使用者可以學習良好文件化的專案，併為不斷發展的開源 LLM 應用生態系統做出貢獻。


#### 主要功能

*  展示了各種 AI 代理，包括入門級和高階的，涵蓋資料分析、醫療影像、音樂生成、旅遊規劃、金融諮詢、投資建議等領域。
*  包含了多代理團隊應用，例如競爭情報、金融、遊戲設計、法律、招聘等，展現了多個 AI 代理協同工作的強大能力。
*  提供了語音 AI 代理應用案例，例如語音導覽、客戶支援等。
*  整合了 MCP AI 代理，能夠與瀏覽器、GitHub、Notion 等平臺整合。
*  包含了多種 RAG 應用，利用不同模型和方法實現檢索增強生成，例如 Agentic RAG、Corrective RAG (CRAG) 以及結合本地和雲端搜尋的混合方案。
*  提供了 LLM 應用記憶體管理教程，例如在 AI 代理中加入記憶功能，實現狀態儲存和個性化體驗。
*  包含了與不同資料來源進行對話的教程，例如 GitHub、Gmail、PDF 檔案、研究論文、Substack 和 YouTube 影片。
*  提供了 Llama 3.2 微調教程。


#### 如何使用

*  本倉庫並非一個單一應用，而是一個收集了眾多 LLM 應用的集合。
*  每個應用的具體使用方法需要參考其各自的 README 檔案和程式碼。
*  部分應用需要安裝特定的依賴庫和模型。
*  部分應用可能需要訪問雲端服務或 API。
*  一些應用可在本地執行，而另一些則需要雲端環境支援。
*  使用者可以根據自己的需求選擇合適的應用進行學習和使用。
*  建議使用者根據自己的技術水平和需求選擇合適的專案開始學習。
*  歡迎使用者為這個開源專案貢獻程式碼和文件。
## 📌 [roboflow/supervision](https://github.com/roboflow/supervision)
<Callout>
    Description: We write your reusable computer vision tools. 💜\
    🌐 Python｜⭐️ 32,893 | 2644 stars this week
</Callout>
    #### 簡介

* Supervision 是一個可重複使用的電腦視覺工具套件，協助使用者處理影像和影片的偵測、計數等任務。
* 支援多種模型 (例如：Ultralytics, Transformers, MMDetection) 與資料集格式 (例如：YOLO, Pascal VOC, COCO)。
* 提供豐富的函式庫，涵蓋模型載入、推論、資料集處理、標註視覺化等功能。
*  支援 Roboflow 整合，方便使用 Roboflow 平臺的資料與模型。


#### 主要功能

* **模型整合 (Model Connectors):**  支援多種熱門電腦視覺模型框架，例如 Ultralytics YOLO, Transformers 等，方便使用者整合自身模型。
* **推論 (Inference):**  提供簡潔的推論介面，支援使用 Roboflow API 進行模型推論。
* **標註器 (Annotators):** 提供多種客製化標註器，讓使用者能視需求調整影像標註的呈現方式，例如顯示邊界框 (bounding boxes)。
* **資料集處理 (Dataset Management):** 提供函式庫處理各種常見的資料集格式 (YOLO, Pascal VOC, COCO)，包含載入、分割、合併、儲存等功能。


#### 如何使用

* 使用 pip 安裝 `supervision` 套件: `pip install supervision`
* 載入影像: 使用 `cv2.imread(...)` 載入影像。
* 載入模型:  使用 `sv.Detections.from_ultralytics(result)` 或 `sv.Detections.from_inference(result)` 從不同來源載入偵測結果。
* 使用 `sv` 模組中的函式處理資料集，例如 `sv.DetectionDataset.from_coco()` 載入 COCO 格式資料集，`dataset.split()` 分割資料集，`dataset.as_yolo()` 儲存為 YOLO 格式。
* 使用 `sv` 模組中的標註器 (Annotators)  例如 `sv.BoxAnnotator()` 將偵測結果標註到影像上。
## 📌 [QwenLM/Qwen3-Coder](https://github.com/QwenLM/Qwen3-Coder)
<Callout>
    Description: Qwen3-Coder is the code version of Qwen3, the large language model series developed by Qwen team, Alibaba Cloud.\
    🌐 Python｜⭐️ 10,943 | 1720 stars this week
</Callout>
    #### 簡介

Qwen3-Coder 是一個強大的程式碼模型，提供多種尺寸的版本，其中 Qwen3-Coder-480B-A35B-Instruct 是目前最強大的版本，擁有 480B 引數和 35B 活性引數的 Mixture-of-Experts 模型。它在 Agentic Coding、Agentic Browser-Use 和 Agentic Tool-Use 等任務上表現出色，與 Claude Sonnet 旗鼓相當。  該模型支援長上下文理解和生成，原生支援 256K tokens，可透過 Yarn 擴充套件至 1M tokens，並支援 358 種程式語言，保留了基礎模型在數學和一般能力方面的優勢。


#### 主要功能

* 支援長上下文 (Long-context Capabilities): 原生支援 256K tokens，可擴充套件至 1M tokens。
* 支援多種程式語言 (Supporting 358 coding languages): 包括但不限於 Python, Java, C++, JavaScript 等。
* Agentic Coding: 支援多個平臺，例如 Qwen Code 和 CLINE，並具有專門設計的函式呼叫格式。
* 高效能 (Significant Performance): 在 Agentic Coding、Agentic Browser-Use 等任務上表現出色，與 Claude Sonnet 水平相當。
* 保留基礎模型的優勢 (Retain strengths in math and general capabilities): 在數學和一般能力方面表現良好。
* 支援 Fill-in-the-middle (FIM) 任務: 可用於程式碼補全。
* 使用新的工具解析器 `qwen3coder_tool_parser.py`。
* 使用更新的特殊 tokens 和 token IDs，與 Qwen3 保持一致。


#### 如何使用

* **與 Qwen3-Coder 進行對話:** 使用 Transformers 框架，透過 `AutoModelForCausalLM` 和 `AutoTokenizer` 載入模型和分詞器，利用 `apply_chat_template` 函式將訊息轉換成模型可理解的格式，並使用 `generate` 方法生成回覆。  範例程式碼已提供。
* **進行程式碼補全 (Fill-in-the-middle):**  使用 `<|fim_prefix|>`, `<|fim_suffix|>`, `<|fim_middle|>` 作為提示詞的標記，將需要補全的程式碼放在對應位置。  範例程式碼已提供，並需注意使用更新的分詞器和特殊 tokens。  所有版本的 Qwen3-Coder 都支援 FIM。
* 模型下載：從 Hugging Face 或 ModelScope 平臺下載模型權重檔案。  請注意使用更新的 tokenizer。
## 📌 [tldr-pages/tldr](https://github.com/tldr-pages/tldr)
<Callout>
    Description: 📚 Collaborative cheatsheets for console commands\
    🌐 Markdown｜⭐️ 58,206 | 1684 stars this week
</Callout>
    #### 簡介

tldr-pages 是一個社群維護的命令列工具說明頁面集合，旨在作為傳統 man pages 的簡潔易懂補充。它提供簡化且易於閱讀的命令說明，特別針對那些不熟悉命令列或需要快速參考命令引數的使用者。此專案涵蓋各種作業系統的命令列工具，例如 UNIX、Linux、macOS、FreeBSD、NetBSD、OpenBSD、SunOS、Android、Windows 和 Cisco IOS。tldr-pages 的目標是提供更實用的範例，讓使用者更容易理解和使用命令列工具。


#### 主要功能

* 提供簡潔易懂的命令列工具說明頁面，比傳統 man pages 更易於上手。
* 涵蓋多種作業系統 (UNIX, Linux, macOS, FreeBSD, NetBSD, OpenBSD, SunOS, Android, Windows, Cisco IOS) 的常見命令列工具。
* 使用 Markdown 編寫頁面，方便編輯和貢獻。
* 提供多種存取方式，包括網頁客戶端 (https://tldr.inbrowser.app)、Python 客戶端、Rust 客戶端、Node.js 客戶端和 PDF 版本。
* 支援多語言翻譯。
* 歡迎社群貢獻，包括新增命令、改進內容、翻譯等。


#### 如何使用

* **網頁瀏覽器:**  直接瀏覽 https://tldr.inbrowser.app (支援離線功能)。
* **Python 客戶端:** 使用 `pip3 install tldr` 安裝並使用 `tldr <command>` 命令。
* **Rust 客戶端:** 使用 Homebrew (或其他套件管理器) 安裝 `tlrc`，然後使用 `tlrc <command>` 命令。
* **Node.js 客戶端:** 使用 `npm install -g tldr` 安裝，然後使用 `tldr <command>` 命令。(但更新較慢)
* **PDF 版本:** 下載最新的 PDF 版本 (支援多種語言)。
*  若要貢獻，請參閱貢獻指南並提交 pull request。  翻譯頁面請訪問 https://lukwebsforge.github.io/tldri18n/。
## 📌 [linshenkx/prompt-optimizer](https://github.com/linshenkx/prompt-optimizer)
<Callout>
    Description: 一款提示词优化器，助力于编写高质量的提示词\
    🌐 TypeScript｜⭐️ 11,968 | 1659 stars this week
</Callout>
    #### 簡介

Prompt Optimizer 是一款強大的AI提示詞最佳化工具，旨在提升AI輸出品質。它支援Web應用、桌面應用、Chrome外掛和Docker部署四種使用方式，能有效協助使用者撰寫更佳的AI提示詞，從而獲得更理想的AI回應。  核心功能包含提示詞智慧最佳化、雙模式最佳化（系統提示詞與使用者提示詞）、原始與最佳化提示詞的即時對比測試，並支援多種主流AI模型，例如OpenAI、Gemini、DeepSeek等。  此外，它採用純客戶端處理架構，確保資料安全，並提供訪問控制功能，提升部署安全性。


#### 主要功能

* 智慧最佳化提示詞，支援多輪迭代改進，提升AI回應準確度。
* 提供系統提示詞和使用者提示詞兩種最佳化模式，滿足不同使用情境。
* 支援原始提示詞與最佳化後提示詞的即時比較，直觀呈現最佳化效果。
* 整合OpenAI、Gemini、DeepSeek、智譜AI、SiliconFlow等主流AI模型。
* 採用純客戶端處理，資料直接與AI服務商互動，不經過中間伺服器，確保資料安全。
* 支援Web應用、桌面應用程式、Chrome外掛及Docker部署，提供多端使用選項。
* 提供密碼保護功能，保障部署安全性。
* 支援Model Context Protocol (MCP)協議，可與Claude Desktop等MCP相容應用程式整合。


#### 如何使用

* **線上版本:** 直接訪問 `https://prompt.always200.com` 使用，所有資料僅儲存在瀏覽器本地。
* **Vercel 部署:** 可透過一鍵部署或Fork專案後在Vercel匯入，需設定環境變數，例如 `ACCESS_PASSWORD` (訪問密碼) 及各AI服務商的API金鑰。
* **桌面應用程式:** 從GitHub Releases下載最新版本，安裝程式版本支援自動更新。
* **Chrome外掛:** 從Chrome商店安裝 (可能非最新版本)。
* **Docker部署:** 使用 `docker run` 指令部署，可設定環境變數配置API金鑰及訪問密碼。  也支援Docker Compose部署，提供更彈性的配置方式。
* **MCP Server 使用:**  透過Docker部署時，MCP Server會自動啟動，可透過`/mcp`路徑訪問。需配置API金鑰及其他相關設定。  可與Claude Desktop等應用整合。
* **API金鑰配置:** 可透過應用程式介面或環境變數設定各AI模型的API金鑰及高階LLM引數 (例如 `llmParams`)。
* **本地開發:**  需克隆專案、安裝依賴項，並使用 `pnpm dev` 命令啟動開發伺服器。
